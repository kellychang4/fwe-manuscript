{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as op\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "  \"text.usetex\": False,\n",
    "  \"font.family\": \"Helvetica\",\n",
    "  \"font.size\": 14\n",
    "})\n",
    "\n",
    "def plot_ribbon(ax, x, y, s, color, alpha = 0.25, label = None):\n",
    "  ax.fill_between(x, y - s, y + s, color = color,\n",
    "                  edgecolor = None, alpha = alpha)\n",
    "  ax.plot(x, y, color = color, label = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_data = op.join(\"/path\", \"to\", \"data\")\n",
    "paths_save = op.join(\"paths\", \"to\", \"figure11\")\n",
    "os.makedirs(paths_save, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = [\"multi-shell\", \"single-shell\"]\n",
    "method_list  = [\"Original\", \"FWE\", \"MSMT\"]\n",
    "suffix_list  = [\"ytrue\", \"ypred\", \"yprob\"] \n",
    "\n",
    "conds = itertools.product(dataset_list, method_list, suffix_list)\n",
    "\n",
    "df_boot = dict() # initialize\n",
    "for dataset, method, suffix in conds: # for each condition\n",
    "  fname = f\"figure11_{dataset}_method-{method}_{suffix}.npy\"\n",
    "  df_boot[(dataset, method, suffix)] = np.load(op.join(paths_data, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate averaged over repeats: MAE, Correlation, and R2\n",
    "df_metrics = {} # initialize\n",
    "\n",
    "for dataset in dataset_list: # for each dataset and tract\n",
    "  print(f\"Dataset: [{dataset}] ----------------------------------------------\")\n",
    "  for method in method_list: # for each method\n",
    "    curr_key = (dataset, method)\n",
    "    y_true = df_boot[curr_key + (\"ytrue\",)]\n",
    "    y_pred = df_boot[curr_key + (\"ypred\",)]\n",
    "    n_repeats = y_true.shape[1] # number of repeats\n",
    "    \n",
    "    mae = np.empty(n_repeats); corr = np.empty(n_repeats); r2 = np.empty(n_repeats)\n",
    "    for i in np.arange(n_repeats): # for each repeat\n",
    "      i_true, i_pred = y_true[:,i], y_pred[:,i] # current true and predicted values\n",
    "      mae[i]  = np.mean(np.abs(i_true - i_pred)) # mean absolute error\n",
    "      corr[i] = np.corrcoef(i_true, i_pred)[0,1] # correlation\n",
    "      r2[i]   = r2_score(i_true, i_pred) # R2 score\n",
    "    \n",
    "    df_metrics[(dataset, method)] = {\"mae\": mae, \"corr\": corr, \"r2\": r2}\n",
    "\n",
    "    stats_str = f\"{method:9s}: MAE = {mae.mean():0.4f} ({mae.std():0.4f}), \"\n",
    "    stats_str += f\"r = {corr.mean():0.4f} ({corr.std():0.4f}), \"\n",
    "    stats_str += f\"R2 = {r2.mean():0.4f} ({r2.std():0.4f})\"\n",
    "    print(stats_str) # print statistics\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_list = [\n",
    "  [(2), (3, 4, 5, 6)],\n",
    "  [(2, 3), (4, 5, 6)], \n",
    "  [(2, 3, 4), (5, 6)], \n",
    "  [(2, 3, 4, 5), (6)], \n",
    "]\n",
    "\n",
    "# false positive rate, resampled to 100 points\n",
    "x_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "df_prob = [] # initialize \n",
    "for i, (label_a, label_b) in enumerate(pair_list): # for each pair of fazekas scores  \n",
    "\n",
    "  conds = itertools.product(dataset_list, method_list)\n",
    "  for dataset, method in conds: # for each condition\n",
    "    # get true labels, predicted probabilities, and unique labels\n",
    "    curr_key = (dataset, method)\n",
    "    y_true   = df_boot[curr_key + (\"ytrue\",)] # true labels\n",
    "    y_prob   = df_boot[curr_key + (\"yprob\",)] # predictded probabilities\n",
    "    y_labels = np.unique(y_true) # unique labels\n",
    "\n",
    "    # get column indices of pair A and B\n",
    "    indx_a = np.where(np.isin(y_labels, label_a))[0]\n",
    "    indx_b = np.where(np.isin(y_labels, label_b))[0]\n",
    "\n",
    "    # get predicted probabilities of pair A and B\n",
    "    yprob_a = y_prob[:,indx_a,:].sum(axis = 1)\n",
    "    yprob_b = y_prob[:,indx_b,:].sum(axis = 1)\n",
    "\n",
    "    # get true labels for pair A and B (as float)\n",
    "    ytrue_a = np.isin(y_true, label_a) * 1.0 \n",
    "    ytrue_b = np.isin(y_true, label_b) * 1.0\n",
    "\n",
    "    n_repeats = ytrue_a.shape[1] # number of repeats\n",
    "    tpr_ab = np.empty((len(x_fpr), n_repeats)) # initialize\n",
    "    auc_ab = np.empty(n_repeats) # initialize\n",
    "    for i in np.arange(n_repeats): # for each repeat\n",
    "      # calculate ROC curves and AUC for group A and B\n",
    "      fpr_a, tpr_a, _ = roc_curve(ytrue_a[:,i], yprob_a[:,i]); auc_a = auc(fpr_a, tpr_a) \n",
    "      fpr_b, tpr_b, _ = roc_curve(ytrue_b[:,i], yprob_b[:,i]); auc_b = auc(fpr_b, tpr_b)\n",
    "\n",
    "      # calulate the average between the two ROCs\n",
    "      tpr_a = np.interp(x_fpr, fpr_a, tpr_a)\n",
    "      tpr_b = np.interp(x_fpr, fpr_b, tpr_b)\n",
    "      tpr_ab[:,i] = (tpr_a + tpr_b) / 2\n",
    "      auc_ab[i] = auc(x_fpr, tpr_ab[:,i])\n",
    "\n",
    "    # store predicted probabilities in dictionary\n",
    "    df_prob.append({\n",
    "      \"dataset\": dataset,\n",
    "      \"method\": method,  \n",
    "      \"pair\": f\"{label_a} vs. {label_b}\",\n",
    "      \"ytrue_a\": ytrue_a, \"ytrue_b\": ytrue_b,\n",
    "      \"yprob_a\": yprob_a, \"yprob_b\": yprob_b, \n",
    "      \"tpr_ab\": tpr_ab,\n",
    "      \"auc_ab\": auc_ab\n",
    "    })\n",
    "\n",
    "df_prob = pd.DataFrame(df_prob)\n",
    "df_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_order = [\n",
    "  \"2 vs. (3, 4, 5, 6)\",\n",
    "  \"(2, 3) vs. (4, 5, 6)\",\n",
    "  \"(2, 3, 4) vs. (5, 6)\",\n",
    "  \"(2, 3, 4, 5) vs. 6\", \n",
    "]\n",
    "\n",
    "method_color = {\n",
    "  \"FWE\": \"red\", \n",
    "  \"MSMT\": \"blue\",\n",
    "  \"Original\": \"green\", \n",
    "}\n",
    "\n",
    "fig_width = len(pair_order) * 5\n",
    "for dataset, df_dataset in df_prob.groupby(\"dataset\"): # for each dataset\n",
    "  fig, ax = plt.subplots(1, len(pair_order), figsize = (fig_width, 6), tight_layout = True)\n",
    "  for (pair, method), df_group in df_dataset.groupby([\"pair\", \"method\"]): # for each pair and method\n",
    "    # extract average true positive rates (mean, sem of repeat distribution)\n",
    "    tpr_ab = df_group[\"tpr_ab\"].values[0]\n",
    "    y_tpr = tpr_ab.mean(axis = 1)\n",
    "    s_tpr = tpr_ab.std(axis = 1) / np.sqrt(tpr_ab.shape[1])\n",
    "\n",
    "    # extract AUC values (mean, sem of repeat distribution)\n",
    "    auc_ab = df_group[\"auc_ab\"].values[0]\n",
    "    y_auc = auc_ab.mean()\n",
    "    s_auc = auc_ab.std() / np.sqrt(auc_ab.shape[-1])\n",
    "\n",
    "    # determine the figure panel index\n",
    "    curr_ax = ax[pair_order.index(pair)] # panel index\n",
    "    curr_ax.plot([0, 1], [0, 1], color = \"black\", linestyle = \"--\") # diagonal line\n",
    "    plot_ribbon(curr_ax, x = x_fpr, y = y_tpr, s = s_tpr, \n",
    "                alpha = 0.15, color = method_color[method],\n",
    "                label = f\"{method} (AUC = {y_auc:0.2f})\")\n",
    "    curr_ax.set_xlabel(\"False Positive Rate\")\n",
    "    curr_ax.set_ylabel(\"True Positive Rate\")\n",
    "    curr_ax.legend(loc = \"lower right\")\n",
    "    curr_ax.set_aspect(\"equal\", \"box\")\n",
    "    curr_ax.set_title(pair) # set title\n",
    "  plt.show()\n",
    "\n",
    "  save_name = f\"figure11_{dataset}_ROC.svg\"\n",
    "  fig.savefig(op.join(paths_save, save_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "act",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

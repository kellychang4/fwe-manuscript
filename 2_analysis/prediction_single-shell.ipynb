{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as op\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_data = op.join(\"/path\", \"to\", \"data\")\n",
    "paths_save = op.join(\"paths\", \"to\", \"output\")\n",
    "os.makedirs(paths_save, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo = pd.read_csv(op.join(paths_data, \"demographics.csv\"))\n",
    "df_demo = df_demo[[\"participant\", \"age\"]]\n",
    "df_demo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.read_csv(op.join(paths_data, \"fazekas_scores.csv\"))\n",
    "df_scores = df_scores[[\"participant\", \"total\"]].rename(columns = {\"total\": \"fazekas\"})\n",
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(op.join(paths_data, \"profiles.csv\"))\n",
    "df = df.merge(df_scores, on = \"participant\")\n",
    "df = df.merge(df_demo, on = \"participant\")\n",
    "df = df[df[\"dataset\"] == \"single-shell\"]\n",
    "df = df[df[\"method\"].isin([\"afq-original\", \"afq-fwe\", \"afq-msmt\"])]\n",
    "df[\"method\"] = df[\"method\"].str.removeprefix(\"afq-\").str.upper()\n",
    "df = df[df[\"metric\"].isin([\"DTI-FA\", \"DTI-MD\"])]\n",
    "df = df[df[\"fazekas\"] > 1] # only two participants with fazekas 1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {} # intialize dictionary \n",
    "for key, df_group in df.groupby(\"method\"):\n",
    "  df_group = (df_group.pivot(\n",
    "    index = [\"participant\", \"fazekas\", \"age\"], \n",
    "    columns = [\"tract\", \"metric\", \"node\"], \n",
    "    values = \"value\")\n",
    "    .reset_index())\n",
    "  df_dict[key] = df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_names = predictor names, y_names = target names\n",
    "x_names = [x for x in df_dict[\"ORIGINAL\"].columns \n",
    "           if x[0] not in [\"participant\", \"fazekas\"]]\n",
    "y_names = \"fazekas\"\n",
    "\n",
    "# define number of cross-validation folds and repeats\n",
    "n_splits  = 5\n",
    "n_repeats = 1000\n",
    "\n",
    "# define k-fold cross-validation method\n",
    "random.seed() # initialize random seed\n",
    "random_state = random.randint(0, 1e5) # random number generator\n",
    "print(f\"Random state: {random_state}\")\n",
    "kfold = RepeatedStratifiedKFold(\n",
    "  n_splits = n_splits, n_repeats = n_repeats, random_state = random_state)\n",
    "\n",
    "\n",
    "# create method feature and label variables\n",
    "X = df_dict[\"ORIGINAL\"][x_names].values\n",
    "y = df_dict[\"ORIGINAL\"][y_names].values\n",
    "\n",
    "df_loops = [] # initialize\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "  i_repeat = (i // n_splits) + 1 # current repeat\n",
    "  i_fold   = (i % n_splits) + 1  # current fold\n",
    "\n",
    "  df_loops.append({\n",
    "    \"repeat\": i_repeat, \"fold\": i_fold, \n",
    "    \"train_index\": train_index, \n",
    "    \"test_index\": test_index\n",
    "  })\n",
    "\n",
    "df_loops = pd.DataFrame(df_loops)\n",
    "df_loops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define current method\n",
    "method = \"ORIGINAL\"\n",
    "\n",
    "# create estimator pipeline\n",
    "pipeline = Pipeline([\n",
    "  (\"imputer\", SimpleImputer(strategy = \"median\")),\n",
    "  (\"z-score\", StandardScaler()),\n",
    "  (\"PCA\", PCA()), \n",
    "  (\"estimator\", LogisticRegressionCV(\n",
    "    Cs           = 10, \n",
    "    cv           = 3, \n",
    "    penalty      = \"l2\",\n",
    "    solver       = \"lbfgs\", \n",
    "    max_iter     = 1000, \n",
    "    class_weight = \"balanced\",\n",
    "    n_jobs       = -1, \n",
    "    multi_class  = \"multinomial\")) \n",
    "])\n",
    "\n",
    "# create method feature and label variables\n",
    "X = df_dict[method][x_names].values\n",
    "y = df_dict[method][y_names].values\n",
    "\n",
    "for i_repeat, df_repeat in df_loops.groupby(\"repeat\"): # for each repeat\n",
    "  # initialize predictions arrays\n",
    "  y_true = np.ones(y.shape) * np.nan\n",
    "  y_pred = np.ones(y.shape) * np.nan\n",
    "  y_prob = np.ones(y.shape + (5,)) * np.nan\n",
    "\n",
    "  for _, (_, _, train_index, test_index) in df_repeat.iterrows(): # for each fold/row\n",
    "    # split data into training and testing set  \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # train model and predict on training split\n",
    "    if \"pipeline_clone\" in locals(): del pipeline_clone # delete pipeline clone\n",
    "    pipeline_clone = sklearn.base.clone(pipeline) # copy pipeline\n",
    "    pipeline_clone.fit(X_train, y_train) # fit model\n",
    "\n",
    "    # predict and store prediction on test set\n",
    "    y_true[test_index]   = y_test # store true values\n",
    "    y_pred[test_index]   = pipeline_clone.predict(X_test)\n",
    "    y_prob[test_index,:] = pipeline_clone.predict_proba(X_test)\n",
    "\n",
    "  curr_save = op.join(paths_save, \"single-shell\", method)\n",
    "  os.makedirs(curr_save, exist_ok = True)\n",
    "\n",
    "  base_name = f\"figure11_single-shell_method-{method}\"\n",
    "  base_name += f\"_repeat-{i_repeat:04d}\"\n",
    "\n",
    "  save_name = f\"{base_name}_ytrue.npy\"\n",
    "  np.save(op.join(curr_save, save_name), y_true)\n",
    "  print(f\"Saved: {save_name}\")\n",
    "\n",
    "  save_name = f\"{base_name}_ypred.npy\"\n",
    "  np.save(op.join(curr_save, save_name), y_pred)\n",
    "  print(f\"Saved: {save_name}\")\n",
    "\n",
    "  save_name = f\"{base_name}_yprob.npy\"\n",
    "  np.save(op.join(curr_save, save_name), y_prob)\n",
    "  print(f\"Saved: {save_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define current method\n",
    "method = \"FWE\"\n",
    "\n",
    "# create estimator pipeline\n",
    "pipeline = Pipeline([\n",
    "  (\"imputer\", SimpleImputer(strategy = \"median\")),\n",
    "  (\"z-score\", StandardScaler()),\n",
    "  (\"PCA\", PCA()), \n",
    "  (\"estimator\", LogisticRegressionCV(\n",
    "    Cs           = 10, \n",
    "    cv           = 3, \n",
    "    penalty      = \"l2\",\n",
    "    solver       = \"lbfgs\", \n",
    "    max_iter     = 1000, \n",
    "    class_weight = \"balanced\",\n",
    "    n_jobs       = -1, \n",
    "    multi_class  = \"multinomial\")) \n",
    "])\n",
    "\n",
    "# create method feature and label variables\n",
    "X = df_dict[method][x_names].values\n",
    "y = df_dict[method][y_names].values\n",
    "\n",
    "for i_repeat, df_repeat in df_loops.groupby(\"repeat\"): # for each repeat\n",
    "  # initialize predictions arrays\n",
    "  y_true = np.ones(y.shape) * np.nan\n",
    "  y_pred = np.ones(y.shape) * np.nan\n",
    "  y_prob = np.ones(y.shape + (5,)) * np.nan\n",
    "\n",
    "  for _, (_, _, train_index, test_index) in df_repeat.iterrows(): # for each fold/row\n",
    "    # split data into training and testing set  \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # train model and predict on training split\n",
    "    if \"pipeline_clone\" in locals(): del pipeline_clone # delete pipeline clone\n",
    "    pipeline_clone = sklearn.base.clone(pipeline) # copy pipeline\n",
    "    pipeline_clone.fit(X_train, y_train) # fit model\n",
    "\n",
    "    # predict and store prediction on test set\n",
    "    y_true[test_index]   = y_test # store true values\n",
    "    y_pred[test_index]   = pipeline_clone.predict(X_test)\n",
    "    y_prob[test_index,:] = pipeline_clone.predict_proba(X_test)\n",
    "\n",
    "  curr_save = op.join(paths_save, \"single-shell\", method)\n",
    "  os.makedirs(curr_save, exist_ok = True)\n",
    "\n",
    "  base_name = f\"figure11_single-shell_method-{method}\"\n",
    "  base_name += f\"_repeat-{i_repeat:04d}\"\n",
    "\n",
    "  save_name = f\"{base_name}_ytrue.npy\"\n",
    "  np.save(op.join(curr_save, save_name), y_true)\n",
    "  print(f\"Saved: {save_name}\")\n",
    "\n",
    "  save_name = f\"{base_name}_ypred.npy\"\n",
    "  np.save(op.join(curr_save, save_name), y_pred)\n",
    "  print(f\"Saved: {save_name}\")\n",
    "\n",
    "  save_name = f\"{base_name}_yprob.npy\"\n",
    "  np.save(op.join(curr_save, save_name), y_prob)\n",
    "  print(f\"Saved: {save_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define current method\n",
    "method = \"MSMT\"\n",
    "\n",
    "# create estimator pipeline\n",
    "pipeline = Pipeline([\n",
    "  (\"imputer\", SimpleImputer(strategy = \"median\")),\n",
    "  (\"z-score\", StandardScaler()),\n",
    "  (\"PCA\", PCA()), \n",
    "  (\"estimator\", LogisticRegressionCV(\n",
    "    Cs           = 10, \n",
    "    cv           = 3, \n",
    "    penalty      = \"l2\",\n",
    "    solver       = \"lbfgs\", \n",
    "    max_iter     = 1000, \n",
    "    class_weight = \"balanced\",\n",
    "    n_jobs       = -1, \n",
    "    multi_class  = \"multinomial\")) \n",
    "])\n",
    "\n",
    "# create method feature and label variables\n",
    "X = df_dict[method][x_names].values\n",
    "y = df_dict[method][y_names].values\n",
    "\n",
    "for i_repeat, df_repeat in df_loops.groupby(\"repeat\"): # for each repeat\n",
    "  # initialize predictions arrays\n",
    "  y_true = np.ones(y.shape) * np.nan\n",
    "  y_pred = np.ones(y.shape) * np.nan\n",
    "  y_prob = np.ones(y.shape + (5,)) * np.nan\n",
    "\n",
    "  for _, (_, _, train_index, test_index) in df_repeat.iterrows(): # for each fold/row\n",
    "    # split data into training and testing set  \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # train model and predict on training split\n",
    "    if \"pipeline_clone\" in locals(): del pipeline_clone # delete pipeline clone\n",
    "    pipeline_clone = sklearn.base.clone(pipeline) # copy pipeline\n",
    "    pipeline_clone.fit(X_train, y_train) # fit model\n",
    "\n",
    "    # predict and store prediction on test set\n",
    "    y_true[test_index]   = y_test # store true values\n",
    "    y_pred[test_index]   = pipeline_clone.predict(X_test)\n",
    "    y_prob[test_index,:] = pipeline_clone.predict_proba(X_test)\n",
    "\n",
    "  curr_save = op.join(paths_save, \"single-shell\", method)\n",
    "  os.makedirs(curr_save, exist_ok = True)\n",
    "\n",
    "  base_name = f\"figure11_single-shell_method-{method}\"\n",
    "  base_name += f\"_repeat-{i_repeat:04d}\"\n",
    "\n",
    "  save_name = f\"{base_name}_ytrue.npy\"\n",
    "  np.save(op.join(curr_save, save_name), y_true)\n",
    "  print(f\"Saved: {save_name}\")\n",
    "\n",
    "  save_name = f\"{base_name}_ypred.npy\"\n",
    "  np.save(op.join(curr_save, save_name), y_pred)\n",
    "  print(f\"Saved: {save_name}\")\n",
    "\n",
    "  save_name = f\"{base_name}_yprob.npy\"\n",
    "  np.save(op.join(curr_save, save_name), y_prob)\n",
    "  print(f\"Saved: {save_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "act",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
